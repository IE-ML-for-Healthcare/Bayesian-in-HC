{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a2951",
   "metadata": {},
   "source": [
    "MARKDOWN CELL:\n",
    "# ðŸšªðŸšªðŸšª The Monty Hall Problem: Frequentist Simulation vs. Bayesian Analysis\n",
    "\n",
    "This notebook tackles the classic **Monty Hall Problem** to demonstrate two fundamental, yet complementary, approaches to probability and inference:\n",
    "\n",
    "* **Frequentist (Monte Carlo Simulation)**: Estimating probabilities through the long-run relative frequency of outcomes in repeated, independent trials (simulations).\n",
    "* **Bayesian (Bayes' Theorem)**: Updating our initial belief (**prior**) about an outcome based on new evidence (**likelihood**) to form a refined belief (**posterior**).\n",
    "\n",
    "## ðŸ“Œ Classical Monty Hall Setup\n",
    "\n",
    "1.  **Three Doors**: One car (the prize) and two goats are placed randomly behind doors 1, 2, and 3\n",
    "2.  **Player's Initial Choice**: The player picks one door, $\\mathbf{D}_{\\text{pick}}$, uniformly at random (could have chosen any one)\n",
    "3.  **Host's Action**: The host (who knows where the car is) opens one of the *other* two doors, $D_{open}$, revealing a goat\n",
    "4.  **The Offer**: The host always offers the player the choice to **stay** with their initial pick or **switch** to the other remaining closed door, $D_{switch}$\n",
    "5.  **Host's Rules (Crucial)**:\n",
    "    * The host must always open one of the doors the player did not pick\n",
    "    * The host must always open a door with a goat (not the one with the car)\n",
    "    * If the host has two goat doors to choose from (i.e. the player's initial pick was the car), the host chooses which goat door to open uniformly at random (50/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960428e",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Learning Goals: Frequentist vs. Bayesian\n",
    "\n",
    "By the end of this exercise, you will be able to:\n",
    "\n",
    "* **Frequentist Insight**: Simulate a process many times to empirically estimate the true underlying probability, demonstrating how **relative frequencies** converge to the **theoretical probability** (Law of Large Numbers)\n",
    "* **Bayesian Insight**: Apply **Bayes' theorem** to formally update an initial **prior belief** ($P(Car)$) using the new evidence provided by the host's action ($P(Host\\text{ opens } Goat)$) to calculate the refined **posterior probability** ($P(Car \\mid Host\\text{ opens } Goat)$)\n",
    "* **Conceptual Clarity**: Explain *why* switching doors is the optimal strategy and demonstrate how both paradigms arrive at the same conclusion: **2/3 probability of winning by switching**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ebda2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the following cell to import libraries and set a reproducible random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.random.seed(42)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2207cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the Monty Hall problem\n",
    "def simulate_monty_hall(n_trials: int) -> dict:\n",
    "    \"\"\"Simulate the classical Monty Hall problem for n_trials.\n",
    "    \n",
    "    Assumptions\n",
    "    - Car is placed uniformly at random behind one of three doors\n",
    "    - Player picks a door uniformly at random\n",
    "    - Host knows the car location, opens a different door that always has a goat\n",
    "    - If host has a choice of two goat doors, he picks one uniformly at random\n",
    "    - Player either always stays or always switches\n",
    "    \n",
    "    Returns counts of wins for stay and for switch\n",
    "    \"\"\"\n",
    "    # Doors encoded as 0,1,2\n",
    "    car_doors = np.random.randint(0, 3, size=n_trials)\n",
    "    picks = np.random.randint(0, 3, size=n_trials)\n",
    "    \n",
    "    # Host opens a goat door that is not the player's pick\n",
    "    host_opens = np.empty(n_trials, dtype=int)\n",
    "    for i in range(n_trials):\n",
    "        available = {0, 1, 2} - {picks[i]}\n",
    "        # remove the car door from available if it is not the player's pick\n",
    "        if car_doors[i] != picks[i]:\n",
    "            available = available - {car_doors[i]}\n",
    "        host_opens[i] = np.random.choice(list(available))\n",
    "    \n",
    "    # The remaining closed door after host opens is:\n",
    "    remaining = 3 - picks - host_opens  # because 0+1+2 = 3 for doors 0,1,2\n",
    "    \n",
    "    stay_wins = np.sum(picks == car_doors)\n",
    "    switch_wins = np.sum(remaining == car_doors)\n",
    "    return {\n",
    "            \"stay_wins\": int(stay_wins), \n",
    "            \"switch_wins\": int(switch_wins), \n",
    "            \"n_trials\": int(n_trials)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6ec23",
   "metadata": {},
   "source": [
    "## Part 1: ðŸ“Š Frequentist Simulation (Monte Carlo)\n",
    "\n",
    "The **Frequentist** approach estimates the probability of an event by running the experiment repeatedly and calculating the **relative frequency** of that event. The Law of Large Numbers dictates that as the number of trials ($N$) grows, the empirical relative frequency converges to the true theoretical probability.\n",
    "\n",
    "We expect:\n",
    "* **Stay Probability**: $1/3$ (since the initial choice is random among three doors).\n",
    "* **Switch Probability**: $2/3$ (since the probability that the car was *not* behind your initial pick is $2/3$, and the host's action transfers that $2/3$ probability to the remaining door)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d60840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final results in a bar chart, comparing empirical rates to theoretical\n",
    "N = 10\n",
    "final_res = simulate_monty_hall(N)\n",
    "\n",
    "# Calculate empirical rates\n",
    "stay_rate_empirical = final_res['stay_wins'] / N\n",
    "switch_rate_empirical = final_res['switch_wins'] / N\n",
    "\n",
    "# Theoretical rates\n",
    "stay_rate_theoretical = 1/3\n",
    "switch_rate_theoretical = 2/3\n",
    "\n",
    "# Data for plotting\n",
    "strategies = ['Stay (Empirical)', 'Stay (Theoretical)', 'Switch (Empirical)', 'Switch (Theoretical)']\n",
    "rates = [stay_rate_empirical, stay_rate_theoretical, switch_rate_empirical, switch_rate_theoretical]\n",
    "colors = ['#4C72B0', '#A9A9A9', '#C44E52', '#A9A9A9'] # Blue for Stay, Red for Switch, Grey for Theoretical\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "bars = plt.bar(strategies, rates, color=colors)\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 1.0) # Set y-limit to 0-1 for probability scale\n",
    "plt.ylabel('Win Probability')\n",
    "plt.title(f'Monty Hall Problem: Final Win Rates After {N} Trials (Frequentist View)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a large batch and compute running means\n",
    "N = 100\n",
    "res = simulate_monty_hall(N) # res is a dict\n",
    "\n",
    "# Re-simulate step by step to get running means for both strategies\n",
    "stay_wins = 0 # of wins when staying\n",
    "switch_wins = 0 # of wins when switching\n",
    "running_stay = np.empty(N) # .empty method for efficiency\n",
    "running_switch = np.empty(N)\n",
    "\n",
    "# We need to iterate to capture the path of convergence\n",
    "car_doors = np.random.randint(0, 3, size=N) # car locations\n",
    "picks = np.random.randint(0, 3, size=N) # player picks\n",
    "host_opens = np.empty(N, dtype=int) # host opens a door\n",
    "for i in range(N):\n",
    "    available = {0, 1, 2} - {picks[i]}\n",
    "    if car_doors[i] != picks[i]:\n",
    "        available = available - {car_doors[i]}\n",
    "    host_opens[i] = np.random.choice(list(available))\n",
    "    remaining = 3 - picks[i] - host_opens[i]\n",
    "    stay_wins += int(picks[i] == car_doors[i])\n",
    "    switch_wins += int(remaining == car_doors[i])\n",
    "    running_stay[i] = stay_wins / (i + 1)\n",
    "    running_switch[i] = switch_wins / (i + 1)\n",
    "\n",
    "print(f\"Total trials: {N}\")\n",
    "print(f\"Stay strategy final win rate: {res['stay_wins'] / N:.4f} (Expected: 0.3333)\")\n",
    "print(f\"Switch strategy final win rate: {res['switch_wins'] / N:.4f} (Expected: 0.6667)\")\n",
    "\n",
    "# Plot convergence of running win rates\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(running_stay, label='Stay win rate')\n",
    "plt.plot(running_switch, label='Switch win rate')\n",
    "plt.axhline(1/3, linestyle='--', label='1/3 reference')\n",
    "plt.axhline(2/3, linestyle='--', label='2/3 reference')\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Empirical probability')\n",
    "plt.title('Monty Hall win rates converge to theoretical values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot convergence of running win rates, zoomed into the first 100 trials\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Using colors consistent with standard plot practices (blue for Stay, orange for Switch based on the plot image)\n",
    "plt.plot(running_stay, label='Empirical Stay Win Rate', color='tab:blue', alpha=0.8)\n",
    "plt.plot(running_switch, label='Empirical Switch Win Rate', color='tab:orange', alpha=0.8)\n",
    "\n",
    "# Applying the colors to the reference lines for clarity\n",
    "plt.axhline(1/3, linestyle='--', color='tab:blue', label='Theoretical 1/3 (Stay)')\n",
    "plt.axhline(2/3, linestyle='--', color='tab:orange', label='Theoretical 2/3 (Switch)')\n",
    "\n",
    "# Zooming into the first 100 trials\n",
    "plt.xlim(0, 100) \n",
    "\n",
    "plt.xlabel('Number of Trials (N)', fontsize=12)\n",
    "plt.ylabel('Empirical Probability (Relative Frequency)', fontsize=12)\n",
    "plt.title('Convergence of Monty Hall Win Rates (Zoomed to 100 Trials)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='center right')\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09665ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate across increasing batch sizes to show approximation quality\n",
    "batch_sizes = [100, 1000, 10000, 100000, 200000]\n",
    "summary = []\n",
    "for n in batch_sizes:\n",
    "    r = simulate_monty_hall(n)\n",
    "    summary.append((n, r['stay_wins'] / n, r['switch_wins'] / n))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(summary, columns=['trials', 'stay_rate', 'switch_rate'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a542934",
   "metadata": {},
   "source": [
    "## Part 2 - Bayesian analysis\n",
    "\n",
    "We compute the posterior probability that your initially chosen door has the car after the host opens a different door to reveal a goat\n",
    "\n",
    "Let\n",
    "- C be the random variable for the door with the car\n",
    "- P be the door you initially pick\n",
    "- H be the event that the host opens a specific goat door\n",
    "\n",
    "Assumptions\n",
    "- Prior P(C = d) = 1/3 for d in {1,2,3}\n",
    "- P is chosen uniformly at random and independent of C\n",
    "- The host always opens a goat door different from P, and if both remaining doors have goats he selects randomly\n",
    "\n",
    "By Bayes theorem\n",
    "\\[ P(C = c \\mid H, P) = \\frac{P(H \\mid C = c, P) P(C = c)}{\\sum_{c'} P(H \\mid C = c', P) P(C = c')} \\]\n",
    "\n",
    "Fix an example: you pick door 1, and the host opens door 3 revealing a goat. Then\n",
    "\n",
    "- If C = 1, host is forced to open door 2 or 3 with equal probability, so P(H = open 3 \\mid C = 1, P = 1) = 1/2\n",
    "- If C = 2, host is forced to open door 3, so P(H = open 3 \\mid C = 2, P = 1) = 1\n",
    "- If C = 3, that would reveal the car, so P(H = open 3 \\mid C = 3, P = 1) = 0\n",
    "\n",
    "With prior P(C = c) = 1/3, the normalized posteriors are\n",
    "\n",
    "- P(C = 1 \\mid H, P) proportional to (1/2) Â· (1/3) = 1/6\n",
    "- P(C = 2 \\mid H, P) proportional to 1 Â· (1/3) = 1/3\n",
    "- P(C = 3 \\mid H, P) proportional to 0 Â· (1/3) = 0\n",
    "\n",
    "After normalization we get P(C = 1 \\mid H, P) = 1/3 and P(C = 2 \\mid H, P) = 2/3. So switching to door 2 wins with probability 2/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the posterior numerically for the example P=1, H=open 3\n",
    "priors = np.array([1/3, 1/3, 1/3])  # for C=1,2,3\n",
    "\n",
    "# Likelihoods P(H=open3 | C=c, P=1)\n",
    "likelihoods = np.array([0.5, 1.0, 0.0])\n",
    "\n",
    "unnormalized = priors * likelihoods\n",
    "posterior = unnormalized / unnormalized.sum()\n",
    "print('Posterior P(C | P=1, H=open 3) =', posterior)\n",
    "print('Probability that switching to door 2 wins =', posterior[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify by enumerating equally likely worlds for P=door 0 and H=open door 2\n",
    "doors = [0, 1, 2]  # 0-based indices for doors 1, 2, 3\n",
    "prior = 1/3\n",
    "\n",
    "num = 0.0\n",
    "den = 0.0\n",
    "for c in doors:         # car position\n",
    "    p = 0               # player picks door 0\n",
    "    # Likelihood P(H=open2 | C=c, P=0)\n",
    "    if c == p:\n",
    "        # Both remaining doors have goats, host chooses randomly, so 1/2 chance of opening door 2\n",
    "        lh = 0.5\n",
    "    elif c == 1:\n",
    "        # Car at door 1, host must open door 2\n",
    "        lh = 1.0\n",
    "    else:\n",
    "        # Car at door 2, host cannot open door 2\n",
    "        lh = 0.0\n",
    "    den += prior * lh\n",
    "    # Switching wins iff car is behind the other closed door, which is door 1 in this event\n",
    "    if c == 1:\n",
    "        num += prior * lh\n",
    "\n",
    "posterior_switch = num / den\n",
    "print('Posterior probability that switching wins (by enumeration) =', posterior_switch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746d80d",
   "metadata": {},
   "source": [
    "## Extensions for exploration\n",
    "\n",
    "Try the following\n",
    "- Change the host policy so he sometimes does not offer a switch and observe how the simulation win rates change\n",
    "- Generalize to N doors and verify that switching wins with probability (N âˆ’ 1)/N\n",
    "- Replace the uniform prior on the car door with a non-uniform prior and recompute the Bayes posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8540a524",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Monty Hall problem, classical assumptions and solutions, Wikipedia https://en.wikipedia.org/wiki/Monty_Hall_problem\n",
    "- Stanford CS109 notes, Conditional Probability and Bayes theorem https://web.stanford.edu/class/archive/cs/cs109/cs109.1246/lectures/04_cond_bayes_annotated.pdf\n",
    "- Wired article with a Python based simulation and discussion of convergence https://www.wired.com/story/monty-hall-problem-python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
