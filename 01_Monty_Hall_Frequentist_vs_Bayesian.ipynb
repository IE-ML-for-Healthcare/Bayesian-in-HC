{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a2951",
   "metadata": {},
   "source": [
    "MARKDOWN CELL:\n",
    "# ðŸšªðŸšªðŸšª The Monty Hall Problem: Frequentist Simulation vs. Bayesian Analysis\n",
    "\n",
    "This notebook tackles the classic **Monty Hall Problem** to demonstrate two fundamental, yet complementary, approaches to probability and inference:\n",
    "\n",
    "* **Frequentist (Monte Carlo Simulation)**: Estimating probabilities through the long-run relative frequency of outcomes in repeated, independent trials (simulations).\n",
    "* **Bayesian (Bayes' Theorem)**: Updating our initial belief (**prior**) about an outcome based on new evidence (**likelihood**) to form a refined belief (**posterior**).\n",
    "\n",
    "## ðŸ“Œ Classical Monty Hall Setup\n",
    "\n",
    "1.  **Three Doors**: One car (the prize) and two goats are placed randomly behind doors 1, 2, and 3\n",
    "2.  **Player's Initial Choice**: The player picks one door, $\\mathbf{D}_{\\text{pick}}$, uniformly at random (could have chosen any one)\n",
    "3.  **Host's Action**: The host (who knows where the car is) opens one of the *other* two doors, $D_{open}$, revealing a goat\n",
    "4.  **The Offer**: The host always offers the player the choice to **stay** with their initial pick or **switch** to the other remaining closed door, $D_{switch}$\n",
    "5.  **Host's Rules (Crucial)**:\n",
    "    * The host must always open one of the doors the player did not pick\n",
    "    * The host must always open a door with a goat (not the one with the car)\n",
    "    * If the host has two goat doors to choose from (i.e. the player's initial pick was the car), the host chooses which goat door to open uniformly at random (50/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960428e",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Learning Goals: Frequentist vs. Bayesian\n",
    "\n",
    "By the end of this exercise, you will be able to:\n",
    "\n",
    "* **Frequentist Insight**: Simulate a process many times to empirically estimate the true underlying probability, demonstrating how **relative frequencies** converge to the **theoretical probability** (Law of Large Numbers)\n",
    "* **Bayesian Insight**: Apply **Bayes' theorem** to formally update an initial **prior belief** ($P(Car)$) using the new evidence provided by the host's action ($P(Host\\text{ opens } Goat)$) to calculate the refined **posterior probability** ($P(Car \\mid Host\\text{ opens } Goat)$)\n",
    "* **Conceptual Clarity**: Explain *why* switching doors is the optimal strategy and demonstrate how both paradigms arrive at the same conclusion: **2/3 probability of winning by switching**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ebda2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the following cell to import libraries and set a reproducible random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ipywidgets as w\n",
    "from IPython.display import display, clear_output\n",
    "np.random.seed(42)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6ec23",
   "metadata": {},
   "source": [
    "## Part 1: ðŸ“Š Frequentist Simulation (Monte Carlo)\n",
    "\n",
    "The **Frequentist** approach estimates the probability of an event by running the experiment repeatedly and calculating the **relative frequency** of that event. The Law of Large Numbers dictates that as the number of trials ($N$) grows, the empirical relative frequency converges to the true theoretical probability.\n",
    "\n",
    "We expect:\n",
    "* **Stay Probability**: $1/3$ (since the initial choice is random among three doors).\n",
    "* **Switch Probability**: $2/3$ (since the probability that the car was *not* behind your initial pick is $2/3$, and the host's action transfers that $2/3$ probability to the remaining door)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53629650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Function to simulate the Monty Hall problem\n",
    "# ---------------------------------------------------------------\n",
    "def simulate_monty_hall(n_trials: int, track_running: bool = False, seed: int | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Simulates the classic Monty Hall game n_trials times.\n",
    "    Optionally tracks the running (cumulative) win rate to show convergence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_trials : int\n",
    "        How many times to repeat the Monty Hall experiment\n",
    "    track_running : bool\n",
    "        If True, store and return running averages to show convergence over time\n",
    "    seed : int | None\n",
    "        Random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with total wins for staying and switching,\n",
    "        and optional arrays of running win rates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a random number generator for reproducibility (better than np.random.seed)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Randomly assign the car behind one of 3 doors (0, 1, or 2) for each trial\n",
    "    car_doors = rng.integers(0, 3, size=n_trials)\n",
    "\n",
    "    # Randomly pick the playerâ€™s initial door (uniform probability)\n",
    "    picks = rng.integers(0, 3, size=n_trials)\n",
    "\n",
    "    # Prepare an empty array to store which door the host opens each time\n",
    "    host_opens = np.empty(n_trials, dtype=int)\n",
    "\n",
    "    # Initialize counters for how many times staying or switching wins\n",
    "    stay_wins = 0\n",
    "    switch_wins = 0\n",
    "\n",
    "    # If we want to track convergence, prepare arrays for running averages\n",
    "    if track_running:\n",
    "        running_stay = np.empty(n_trials, dtype=float)\n",
    "        running_switch = np.empty(n_trials, dtype=float)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Main simulation loop: run the game n_trials times\n",
    "    # ---------------------------------------------------------------\n",
    "    for i in range(n_trials):\n",
    "        # 1. The host can open any door except the one the player picked\n",
    "        available = {0, 1, 2} - {picks[i]}\n",
    "\n",
    "        # 2. But if the car isnâ€™t behind the chosen door,\n",
    "        #    the host must avoid the door hiding the car\n",
    "        if car_doors[i] != picks[i]:\n",
    "            available = available - {car_doors[i]}\n",
    "\n",
    "        # 3. From the remaining doors, the host opens one at random\n",
    "        host_opens[i] = rng.choice(list(available))\n",
    "\n",
    "        # 4. Only one unopened door remains after the host opens a goat door\n",
    "        remaining = 3 - picks[i] - host_opens[i]\n",
    "        # This arithmetic works because 0 + 1 + 2 = 3 (door indices),\n",
    "        # so the remaining door is the one not chosen or opened.\n",
    "\n",
    "        # 5. Check outcomes for both strategies\n",
    "        stay_wins += int(picks[i] == car_doors[i])      # Did staying win?\n",
    "        switch_wins += int(remaining == car_doors[i])    # Did switching win?\n",
    "\n",
    "        # 6. If tracking, update running averages after each trial\n",
    "        if track_running:\n",
    "            running_stay[i] = stay_wins / (i + 1)\n",
    "            running_switch[i] = switch_wins / (i + 1)\n",
    "\n",
    "    # Store results in a dictionary to make it easy to return multiple outputs\n",
    "    out = {\n",
    "        \"stay_wins\": int(stay_wins),\n",
    "        \"switch_wins\": int(switch_wins),\n",
    "        \"n_trials\": int(n_trials)\n",
    "    }\n",
    "\n",
    "    # Add the running arrays if requested (for the convergence plot)\n",
    "    if track_running:\n",
    "        out[\"running_stay\"] = running_stay\n",
    "        out[\"running_switch\"] = running_switch\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cee823",
   "metadata": {},
   "source": [
    "### ðŸ“Š Bar Chart Comparison: Empirical vs. Theoretical\n",
    "\n",
    "To visualize the concept of convergence and the influence of sample size, we use a bar chart to directly compare the **Empirical Win Rate** (what happened in the simulation) against the **Theoretical Win Rate** (what the math predicts).\n",
    "\n",
    "By generating plots with increasing trial counts ($\\mathbf{N}$), we clearly demonstrate how **small samples yield high variability and unreliable results**, while large samples closely match the theoretical prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Function to plot Empirical vs. Theoretical Probabilities\n",
    "# ---------------------------------------------------------------\n",
    "def plot_empirical_vs_theoretical(n_trials: int, seed: int | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot empirical win rates from a simulation next to the theoretical rates\n",
    "    for the Stay vs. Switch strategies using a grouped bar chart.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_trials : int\n",
    "        The number of games simulated to obtain the empirical rates.\n",
    "    seed : int | None\n",
    "        Random seed for simulation reproducibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run the simulator once for a batch of N games, passing the seed for reproducibility\n",
    "    res = simulate_monty_hall(n_trials, track_running=False, seed=seed) \n",
    "\n",
    "    # --- 1. Calculate Rates ---\n",
    "    # Convert simulation counts to empirical probabilities (Frequentist approach)\n",
    "    stay_empirical_rate = res[\"stay_wins\"] / n_trials\n",
    "    switch_empirical_rate = res[\"switch_wins\"] / n_trials\n",
    "\n",
    "    # Theoretical probabilities for the classical Monty Hall setup\n",
    "    stay_theoretical_rate = 1/3\n",
    "    switch_theoretical_rate = 2/3\n",
    "\n",
    "    # --- 2. Prepare Data for Grouped Bars ---\n",
    "    strategies = [\"Stay\", \"Switch\"]\n",
    "    empirical_rates = np.array([stay_empirical_rate, switch_empirical_rate])\n",
    "    theoretical_rates = np.array([stay_theoretical_rate, switch_theoretical_rate])\n",
    "\n",
    "    # Set bar positions and width so Empirical and Theoretical appear side by side\n",
    "    x = np.arange(len(strategies))       # Positions for the two strategy groups (0 and 1)\n",
    "    width = 0.38                         # Width of each bar for side-by-side comparison\n",
    "\n",
    "    # --- 3. Create Plot ---\n",
    "    plt.figure(figsize=(9, 6))\n",
    "\n",
    "    # Draw bars for empirical rates (left bar in each group)\n",
    "    bar1 = plt.bar(\n",
    "        x - width/2, \n",
    "        empirical_rates, \n",
    "        width, \n",
    "        label=\"Empirical Rate\",\n",
    "        color='tab:blue' # Use a solid color for empirical data\n",
    "    )\n",
    "    \n",
    "    # Draw bars for theoretical rates (right bar in each group)\n",
    "    bar2 = plt.bar(\n",
    "        x + width/2, \n",
    "        theoretical_rates, \n",
    "        width, \n",
    "        label=\"Theoretical Rate\",\n",
    "        color='tab:gray', # Use a neutral color for reference data\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # --- 4. Add Value Labels for Clarity ---\n",
    "    def add_labels(bars):\n",
    "        \"\"\"Helper function to add value labels on top of the bars.\"\"\"\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            # Format the label to 3 decimal places\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, \n",
    "                     f\"{yval:.3f}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "    add_labels(bar1)\n",
    "    add_labels(bar2)\n",
    "\n",
    "    # --- 5. Cosmetic Settings ---\n",
    "    plt.xticks(x, strategies)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.ylabel(\"Win Probability\", fontsize=12)\n",
    "    plt.title(f\"Empirical vs. Theoretical Win Rates (Running Avg) After {n_trials} Trials\", \n",
    "              fontsize=14, fontweight=\"bold\")\n",
    "    plt.grid(axis=\"y\", linestyle=\":\", alpha=0.6)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Example Execution: Illustrate convergence by increasing trials\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Try several N to illustrate variability at small samples vs stability at large samples\n",
    "print(\"Generating bar charts to show convergence...\")\n",
    "for N in [\n",
    "    10, \n",
    "    # 100, \n",
    "    # 1000, \n",
    "    # 100000,\n",
    "]:\n",
    "    plot_empirical_vs_theoretical(N, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93710c49",
   "metadata": {},
   "source": [
    "### ðŸ“‰ Full Convergence Plot\n",
    "\n",
    "This plot shows the running average probability over the entire simulation ($\\mathbf{N=200,000}$). This is the essential Frequentist view.\n",
    "\n",
    "Observe how the lines initially jump with high variance (due to chance) but quickly stabilize and converge precisely on the dashed theoretical lines, demonstrating that **switching doors provides a consistent, long-term $\\mathbf{2/3}$ advantage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa188131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Run the simulation and visualize convergence (Frequentist View)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Number of games to simulate\n",
    "N = 200000   # A large number makes the convergence smooth (Law of Large Numbers)\n",
    "\n",
    "# Run the simulation and ask to track running averages\n",
    "# We use a fixed seed (42) for reproducible results\n",
    "res = simulate_monty_hall(N, track_running=True, seed=42)\n",
    "\n",
    "# Print final win rates to compare with theoretical probabilities\n",
    "print(f\"Total trials: {N}\")\n",
    "print(f\"Final stay win rate:   {res['running_stay'][-1]:.4f}  (Expected 1/3 â‰ˆ 0.3333)\")\n",
    "print(f\"Final switch win rate: {res['running_switch'][-1]:.4f}  (Expected 2/3 â‰ˆ 0.6667)\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Plot the convergence of probabilities\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot running averages over trials\n",
    "plt.plot(res[\"running_stay\"], label=\"Empirical Stay Win Rate\", color='tab:blue', alpha=0.8)\n",
    "plt.plot(res[\"running_switch\"], label=\"Empirical Switch Win Rate\", color='tab:orange', alpha=0.8)\n",
    "\n",
    "# Add horizontal dashed lines for theoretical values (the true probabilities)\n",
    "plt.axhline(1/3, linestyle=\"--\", color=\"tab:blue\", label=\"Theoretical 1/3 (Stay)\")\n",
    "plt.axhline(2/3, linestyle=\"--\", color=\"tab:orange\", label=\"Theoretical 2/3 (Switch)\")\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel(\"Number of Trials (N)\", fontsize=12)\n",
    "plt.ylabel(\"Empirical Probability (Running Win Rate)\", fontsize=12)\n",
    "\n",
    "# Add a descriptive title\n",
    "plt.title(\"Monty Hall Win Rates (Running avg) Converge to Theoretical Values\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Display legend and format nicely\n",
    "plt.legend(loc='center right')\n",
    "plt.grid(True, linestyle=':', alpha=0.6, axis='both')\n",
    "plt.tight_layout()\n",
    "plt.xlim(0, min(1000, N)) # Zoom in to show initial convergence\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09665ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate across increasing batch sizes to show approximation quality\n",
    "batch_sizes = [100, 1000, 10000, 100000, 200000]\n",
    "summary = []\n",
    "for n in batch_sizes:\n",
    "    r = simulate_monty_hall(n)\n",
    "    summary.append((n, r['stay_wins'] / n, r['switch_wins'] / n))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(summary, columns=['trials', 'stay_rate', 'switch_rate'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe73034",
   "metadata": {},
   "source": [
    "MARKDOWN CELL:\n",
    "## Part 2: ðŸ§  Bayesian Analysis (Updating Beliefs)\n",
    "\n",
    "The **Bayesian** approach treats probability as a **degree of belief** and uses **Bayes' theorem** to rationally update this belief when **new evidence** is presented.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“ Key Definitions\n",
    "\n",
    "Let:\n",
    "\n",
    "- **C**: Random variable for the door with the **Car** ($C \\in \\{1, 2, 3\\}$). This is the **Hypothesis** of interest: the actual location of the car (of which are 3 - one per door)\n",
    "- **c**: A **Specific Door Number** (e.g. $c=1$ or $c=3$). This is a placeholder for a single outcome of the random variable $C$\n",
    "- **$D$**: The door you initially **Pick** ($\\mathbf{D}_{\\text{pick}}$) (fixed, e.g. $D = 1$). This is fixed and known\n",
    "- **$H$**: The event that the **Host** opens a specific goat door ($\\mathbf{D}_{\\text{open}}$) (e.g. $H = \\text{Host opens Door 3}$). This is the new evidence\n",
    "\n",
    "We want to find the **Posterior Probability** (our updated belief) of the car's location given the evidence $H$ and the initial pick $D$:\n",
    "\n",
    "### ðŸ”¬ Bayes' Theorem (Concise Form)\n",
    "\n",
    "This version of the formula shows that the **Posterior Probability** (the refined belief) is calculated from the **Prior** (initial belief) multiplied by the **Likelihood** (new evidence fit), all divided by the **Evidence** (the normalizing constant).\n",
    "\n",
    "$$\n",
    "\\underbrace{P(C \\mid H, D)}_{\\text{Posterior}} = \\frac{\\overbrace{P(H \\mid C, D)}^{\\text{Likelihood}} \\times \\overbrace{P(C)}^{\\text{Prior}}}{\\underbrace{P(H \\mid D)}_{\\text{Evidence}}}\n",
    "$$\n",
    "\n",
    "### âš™ï¸ Calculating the Posterior: Semi-Full Form\n",
    "\n",
    "$$\n",
    "P(C = c \\mid H, D) = \\frac{P(H \\mid C = c, D)\\, P(C = c)}{P(H \\mid D)}\n",
    "$$\n",
    "\n",
    "| Formula Part | Name | What It Asks | Role in the Update |\n",
    "| :---: | :--- | :--- | :--- |\n",
    "| $P(H \\mid C = c, D)$ | **Likelihood** | What's the probability the host would open door $H$, *if* the car were actually at door $c$? | Measures how well each hypothesis ($C=c$) explains the evidence ($H$). This is the crucial information gained from the host's rules. |\n",
    "| $P(C = c)$ | **Prior** | What's the probability the car is at door $c$ *before* the host opens anything? | Your initial belief ($\\mathbf{1/3}$). |\n",
    "| **$P(H \\mid D)$** | **Evidence** | What is the total probability of seeing the host open door $H$, considering all possibilities for the car's location? | The **Normalizing Constant**. It ensures all posterior probabilities sum to 1. |\n",
    "| $P(C = c \\mid H, D)$ | **Posterior** | What's the probability the car is at door $c$ *after* seeing the host's action $H$? | The **final, updated belief**. This tells you whether to stay or switch. |\n",
    "\n",
    "\"The Probability of the Evidence $H$ given my Pick $D$ ($P(H \\mid D)$) is equal to the SUM ($\\sum$) of the likelihood and prior product for ALL possible car locations ($c'$ in the set $\\{1, 2, 3\\}$).\"\n",
    "\n",
    "$$\n",
    "P(H \\mid D) = \\sum_{c' \\in \\{1, 2, 3\\}} P(H \\mid C = c', D)\\, P(C = c')\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸšª Applying Bayes' Theorem: The Example\n",
    "\n",
    "Let's fix the scenario:\n",
    "\n",
    "1. **Initial Pick**: You choose **Door 1** ($D = 1$) \n",
    "2. **Host's Action**: The host opens **Door 3** ($H = \\text{Host opens Door 3}$), revealing a goat.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Prior Probability, $P(C = c)$\n",
    "\n",
    "Initially, the car is equally likely to be behind any door (a **uniform prior**):\n",
    "\n",
    "$$\n",
    "P(C = 1) = P(C = 2) = P(C = 3) = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Likelihood, $P(H = \\text{open 3} \\mid C = c, D = 1)$\n",
    "\n",
    "This is the probability that the host opens Door 3, *given* the car's actual location $C$. This step is critical, as it incorporates the host's constraints.\n",
    "\n",
    "| Car Location ($C$) | $P(H = \\text{open 3} \\mid C, D = 1)$ | Hostâ€™s Action Rationale | Contribution to Posterior $\\propto P(H \\mid C, D) P(C)$ |\n",
    "|:---:|:---:|:---|:---:|\n",
    "| **$C = 1$** (You were right) | $\\frac{1}{2}$ | Host must open Door 2 or 3 (both have goats). Chooses randomly (50/50). | $(\\frac{1}{2})(\\frac{1}{3}) = \\frac{1}{6}$ |\n",
    "| **$C = 2$** (Switch wins) | $1$ | Host is **forced** to open Door 3 (as Door 2 has the car, and Door 1 was picked). | $(1)(\\frac{1}{3}) = \\frac{1}{3}$ |\n",
    "| **$C = 3$** (Impossible) | $0$ | Host cannot open Door 3 (it has the car). | $(0)(\\frac{1}{3}) = 0$ |\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Posterior Probability, $P(C = c \\mid H, D = 1)$\n",
    "\n",
    "**Total Evidence** (Normalizing Constant):\n",
    "\n",
    "$$\n",
    "P(H \\mid D) = \\frac{1}{6} + \\frac{1}{3} + 0 = \\frac{3}{6} = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "**Posterior probabilities** (After normalization):\n",
    "\n",
    "$$\n",
    "P(C = 1 \\mid H) = \\frac{(1/6)}{(1/2)} = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(C = 2 \\mid H) = \\frac{(1/3)}{(1/2)} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion:** \n",
    "> ### After the evidence (the host opening a goat door), the probability that the car is behind your original door ($\\mathbf{D = 1}$) remains $\\mathbf{1/3}$. The probability that the car is behind the other closed door ($C = 2$) increases to $\\mathbf{2/3}$. Switching doubles your chance of winning!!ðŸš—ðŸ¥³"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb05cd3",
   "metadata": {},
   "source": [
    "## ðŸ’» Interactive Bayesian Visualization\n",
    "\n",
    "The code below implements the exact calculations derived in the previous section. This interactive tool visualizes the **three steps of the Bayesian update** for any valid scenario you select with the dropdowns.\n",
    "\n",
    "1.  **Prior P(C):** The initial $1/3$ belief for every door.\n",
    "2.  **Likelihood $\\times$ Prior (Evidence Applied):** How the host's action transfers probability mass away from the opened door and towards the switch door.\n",
    "3.  **Posterior P(C | H, D):** The final, normalized probability, showing the **$2/3$ switching advantage**.\n",
    "\n",
    "**(Note: The visualization automatically enforces the Host's Rule: the host cannot open the door you picked.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Core math ----------\n",
    "def likelihood_vector_classic(D_idx: int, H_idx: int) -> np.ndarray:\n",
    "    \"\"\"L[c] = P(H | C=c, D) for the classic host who never opens D, never reveals car, randomizes if two goats remain\"\"\"\n",
    "    if H_idx == D_idx:\n",
    "        raise ValueError(\"Host cannot open the player's chosen door\")\n",
    "    doors = {0, 1, 2}\n",
    "    L = np.zeros(3, dtype=float)\n",
    "    for c in range(3):\n",
    "        if c == D_idx:\n",
    "            # HYPOTHESIS: Car is at the Picked Door (C=D). Host must randomize (0.5 chance of opening H).\n",
    "            L[c] = 0.5\n",
    "        else:\n",
    "            # HYPOTHESIS: Car is NOT at the Picked Door (C!=D). Host is forced to open one specific door.\n",
    "            forced = list(doors - {D_idx, c})[0]\n",
    "            L[c] = 1.0 if H_idx == forced else 0.0\n",
    "    return L\n",
    "\n",
    "def bayes_posterior(prior: np.ndarray, like: np.ndarray):\n",
    "    \"\"\"\n",
    "    Applies Bayes' theorem to find the Posterior probability.\n",
    "    Returns: unnormalized contribution, posterior, and evidence (Z).\n",
    "    \"\"\"\n",
    "    un = prior * like\n",
    "    Z = float(un.sum())\n",
    "    if Z == 0:\n",
    "        raise ValueError(\"Zero evidence under supplied prior and likelihood\")\n",
    "    return un, un / Z, Z\n",
    "\n",
    "# ---------- Visualization Helpers ----------\n",
    "def door_schematic(ax, D_idx: int, H_idx: int):\n",
    "    \"\"\"\n",
    "    Draws the door scenario schematic.\n",
    "    Blue = picked door, Red = host opens, Orange = remaining closed.\n",
    "    \"\"\"\n",
    "    ax.set_xlim(0, 3)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis(\"off\")\n",
    "    other_closed = list({0,1,2} - {D_idx, H_idx})[0]\n",
    "    \n",
    "    # Define colors based on the role in the scenario:\n",
    "    colors = [\"white\"] * 3\n",
    "    colors[D_idx] = \"tab:blue\"    # Picked Door (Stay)\n",
    "    colors[H_idx] = \"tab:red\"     # Host Opens Door (Eliminated)\n",
    "    colors[other_closed] = \"tab:orange\" # Other Closed Door (Switch)\n",
    "\n",
    "    # Draw doors and labels\n",
    "    for i in range(3):\n",
    "        rect = plt.Rectangle((i + 0.05, 0.2), 0.9, 0.6, facecolor=colors[i], alpha=0.8)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(i + 0.5, 0.5, f\"Door {i+1}\", ha=\"center\", va=\"center\", fontsize=12, color=\"white\", weight=\"bold\")\n",
    "    \n",
    "    ax.text(0.5, 0.07, \"Initial Pick\", color=\"tab:blue\", ha=\"center\", fontsize=10, weight=\"bold\")\n",
    "    ax.text(1.5, 0.07, \"Host Opens\", color=\"tab:red\", ha=\"center\", fontsize=10, weight=\"bold\")\n",
    "    ax.text(2.5, 0.07, \"Switch Target\", color=\"tab:orange\", ha=\"center\", fontsize=10, weight=\"bold\")\n",
    "\n",
    "def plot_update(D_num: int, H_num: int, message_widget: w.HTML, out: w.Output):\n",
    "    \"\"\"Compute and render the full 3-step update visualization.\"\"\"\n",
    "    D_idx, H_idx = D_num - 1, H_num - 1\n",
    "    prior = np.array([1/3, 1/3, 1/3], dtype=float)\n",
    "\n",
    "    try:\n",
    "        like = likelihood_vector_classic(D_idx, H_idx)\n",
    "        contrib, post, evidence = bayes_posterior(prior, like)\n",
    "        other_closed = list({0,1,2} - {D_idx, H_idx})[0]\n",
    "        \n",
    "        # Labels for the bar charts\n",
    "        labels = [f\"Car at Door {i+1}\" for i in [0,1,2]]\n",
    "        \n",
    "        # Define bar colors: Blue (Stay/Picked), Orange (Switch/Other Closed), Red (Eliminated/Host Opened)\n",
    "        bar_colors = [\"white\"] * 3\n",
    "        bar_colors[D_idx] = \"tab:blue\"\n",
    "        bar_colors[other_closed] = \"tab:orange\"\n",
    "        bar_colors[H_idx] = \"tab:red\"\n",
    "\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            # Text summary\n",
    "            print(f\"Scenario: Player picks Door {D_num}, Host opens Door {H_num}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"P(Stay) Â  = P(Car at Door {D_num}) = {post[D_idx]:.4f} (1/3)\")\n",
    "            print(f\"P(Switch) = P(Car at Door {other_closed+1}) = {post[other_closed]:.4f} (2/3)\")\n",
    "            print(f\"Evidence P(H | D) = {evidence:.4f}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # --- Figure Layout ---\n",
    "            fig = plt.figure(figsize=(15, 6))\n",
    "            # GridSpec creates two rows: one for the schematic, one for the 3 plots\n",
    "            gs = fig.add_gridspec(2, 3, height_ratios=[0.5, 1.2], hspace=0.35)\n",
    "\n",
    "            # Row 1: Door Schematic\n",
    "            ax0 = fig.add_subplot(gs[0, :])\n",
    "            door_schematic(ax0, D_idx, H_idx)\n",
    "\n",
    "            # Row 2, Col 1: Prior P(C)\n",
    "            ax1 = fig.add_subplot(gs[1, 0])\n",
    "            b1 = ax1.bar(labels, prior, color=bar_colors)\n",
    "            ax1.set_ylim(0, 1); \n",
    "            ax1.set_title(\"Step 1: Prior P(C) (Initial Belief)\", fontsize=12, fontweight='bold'); \n",
    "            ax1.tick_params(axis=\"x\", rotation=15, labelsize=9)\n",
    "            for bar in b1: ax1.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.02, f\"{bar.get_height():.3f}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "            # Row 2, Col 2: Unnormalized Contributions P(H|C) P(C)\n",
    "            ax2 = fig.add_subplot(gs[1, 1])\n",
    "            # Set y-limit to clearly show the zero contribution from the host's door\n",
    "            max_contrib = max(contrib.max() * 1.25, 0.45) \n",
    "            b2 = ax2.bar(labels, contrib, color=bar_colors)\n",
    "            ax2.set_ylim(0, max_contrib); \n",
    "            ax2.set_title(\"Step 2: Likelihood * Prior (Evidence Applied)\", fontsize=12, fontweight='bold'); \n",
    "            ax2.tick_params(axis=\"x\", rotation=15, labelsize=9)\n",
    "            for bar in b2:\n",
    "                h = bar.get_height()\n",
    "                if h > 1e-6:\n",
    "                    ax2.text(bar.get_x()+bar.get_width()/2, h+0.02, f\"{h:.3f}\", ha=\"center\", fontsize=9)\n",
    "                else:\n",
    "                    ax2.text(bar.get_x()+bar.get_width()/2, 0.01, f\"{h:.3f}\", ha=\"center\", fontsize=9) # Show the zero clearly\n",
    "\n",
    "            # Row 2, Col 3: Posterior P(C | H, D)\n",
    "            ax3 = fig.add_subplot(gs[1, 2])\n",
    "            b3 = ax3.bar(labels, post, color=bar_colors)\n",
    "            ax3.set_ylim(0, 1); \n",
    "            ax3.set_title(\"Step 3: Posterior P(C | H, D) (Final Belief)\", fontsize=12, fontweight='bold'); \n",
    "            ax3.tick_params(axis=\"x\", rotation=15, labelsize=9)\n",
    "            for bar in b3: ax3.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.02, f\"{bar.get_height():.3f}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    except ValueError as e:\n",
    "        # Catch the intentional error when H=D before the guard corrects it\n",
    "        message_widget.value = f\"<span style='color:#d62728; font-weight:bold;'>Error: {e}. Host cannot open your selected door.</span>\"\n",
    "\n",
    "# ---------- UI wiring and Execution ----------\n",
    "# Use Dropdown for clear options 1, 2, 3\n",
    "pick = w.Dropdown(description=\"Player Pick (D)\", options=[1,2,3], value=1)\n",
    "host = w.Dropdown(description=\"Host Opens (H)\", options=[2,3], value=3) \n",
    "msg  = w.HTML(value=\"\", placeholder=\"messages\")\n",
    "out  = w.Output()\n",
    "\n",
    "def on_pick_change(change):\n",
    "    # Dynamically update host options to exclude the pick\n",
    "    p = change[\"new\"]\n",
    "    new_options = [d for d in [1,2,3] if d != p]\n",
    "    \n",
    "    # Check if the host's current value is now illegal\n",
    "    if host.value == p:\n",
    "        host.value = new_options[0] # Set to the first legal option\n",
    "        msg.value = f\"<span style='color:#d62728;'>Host cannot open your door. Host's option adjusted to Door {host.value}.</span>\"\n",
    "    else:\n",
    "        msg.value = \"\"\n",
    "    host.options = new_options # Update the dropdown options\n",
    "\n",
    "def on_any_change(_):\n",
    "    # This function handles the main plotting on any slider/dropdown value change\n",
    "    plot_update(pick.value, host.value, msg, out)\n",
    "\n",
    "# Observe changes\n",
    "pick.observe(on_pick_change, names=\"value\")\n",
    "pick.observe(on_any_change, names=\"value\")\n",
    "host.observe(on_any_change, names=\"value\")\n",
    "\n",
    "# Initial Render to draw the default scenario\n",
    "on_pick_change({\"new\": pick.value}) # Run the pick change handler once to set host options\n",
    "on_any_change(None) # Render the plot\n",
    "\n",
    "# Display UI\n",
    "display(w.VBox([w.Label(\"Move the sliders (Doors 1, 2, or 3) to see the shift in probability:\"), w.HBox([pick, host]), msg, out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a0947",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74407541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
